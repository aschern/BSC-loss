{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sentence-transformers/examples/datasets/get_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../lib\")\n",
    "\n",
    "from STSDataReaderBinary import STSDataReaderBinary\n",
    "from STSDataReaderBinaryPositives import STSDataReaderBinaryPositives\n",
    "from BSCLoss import BSCLoss, ComboBSCLoss\n",
    "from BSCShuffler import ShuffledSentencesDataset, ShuffledSentenceTransformer\n",
    "from BSCShuffler import BSCShuffler, ModelBSCShuffler, ModelExampleBasedShuffler\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import os\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, evaluation\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, TripletEvaluator, SimilarityFunction\n",
    "from sentence_transformers.readers import *\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=124)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = ShuffledSentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')\n",
    "\n",
    "# or use the trained model\n",
    "#model = ShuffledSentenceTransformer('checkpoints_/bsc_sts')\n",
    "\n",
    "# to train tau\n",
    "# model._first_module().auto_model.config.output_hidden_states = True\n",
    "\n",
    "sts_reader_pos = STSDataReaderBinaryPositives('sentence-transformers/examples/datasets/stsbenchmark', \n",
    "                           s1_col_idx=5, s2_col_idx=6, score_col_idx=4,normalize_scores=True, thr=0.6,\n",
    "                                             get_positives=False)\n",
    "sts_reader = STSDataReader('sentence-transformers/examples/datasets/stsbenchmark', \n",
    "                           s1_col_idx=5, s2_col_idx=6, score_col_idx=4,normalize_scores=True)\n",
    "\n",
    "train_batch_size = 30\n",
    "num_epochs = 5\n",
    "\n",
    "train_data_bsc = ShuffledSentencesDataset(sts_reader_pos.get_examples('sts-train.csv'), model)\n",
    "train_dataloader_bsc = DataLoader(train_data_bsc, shuffle=False, batch_size=train_batch_size)\n",
    "train_loss_bsc = BSCLoss(model=model, tau=0.1)\n",
    "\n",
    "train_data = SentencesDataset(sts_reader.get_examples('sts-train.csv'), model)\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(sts_reader.get_examples('sts-test.csv'), name='sts-test')\n",
    "evaluator.device = 'cuda'\n",
    "evaluator.main_similarity = SimilarityFunction.COSINE\n",
    "evaluator_dev = EmbeddingSimilarityEvaluator.from_input_examples(sts_reader.get_examples('sts-dev.csv'), name='sts-dev')\n",
    "evaluator_dev.device = 'cuda'\n",
    "evaluator_dev.main_similarity = SimilarityFunction.COSINE\n",
    "seq_evaluator = evaluation.SequentialEvaluator([evaluator, evaluator_dev],\n",
    "                                               main_score_function=lambda scores: scores[-1])\n",
    "\n",
    "warmup_steps = math.ceil(len(train_data)*num_epochs/train_batch_size*0.1)\n",
    "model_save_path = 'checkpoints_/bsc-mse_sts'\n",
    "\n",
    "get_ipython().system(\"rm -rf 'checkpoints_/bsc-mse_sts'\")\n",
    "\n",
    "\n",
    "shuffler = ModelExampleBasedShuffler(group_size=7, allow_same=True)\n",
    "#shuffler = ModelBSCShuffler(group_size=7, by_clusters=True, num_clusters=200,\n",
    "#                            file_name=None, output_file_name=None, column_name=None, max_ind=None)#\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader_bsc, train_loss_bsc)],\n",
    "          evaluator=seq_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path,\n",
    "          optimizer_params={'alpha_lr': 0.005, 'lr': 2e-5, 'eps': 1e-6, 'correct_bias': True},\n",
    "          shuffler=shuffler,\n",
    "          shuffle_idxs=[0]\n",
    "         )\n",
    "\n",
    "model = ShuffledSentenceTransformer('checkpoints_/bsc_sts')\n",
    "model.evaluate(evaluator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
